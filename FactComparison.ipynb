{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtcSZK9BqlyuMN7t9ZmR65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theDikshaSaxena/Recontextualization-Detection/blob/main/FactComparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTZtWSaLMCP4"
      },
      "outputs": [],
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "! pip install torchtext==0.10.1\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\")\n",
        "torch.cuda.init()\n",
        "import numpy as np\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpcwl5PlMF1f",
        "outputId": "95e884d0-250c-4697-cb77-0878b7dc9377"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.4\n",
            "    Uninstalling spacy-3.5.4:\n",
            "      Successfully uninstalled spacy-3.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPgunw21Mivi",
        "outputId": "9ea643a1-9264-4727-d7f5-bf9cf122e4ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-31 09:06:00.614781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 09:06:01.802741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.5.0\n",
            "    Uninstalling en-core-web-sm-3.5.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.5.0\n",
            "Successfully installed en-core-web-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract entities of specific types from a paragraph\n",
        "def extract_specific_entities(paragraph, entity_types):\n",
        "    doc = nlp(paragraph)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entity_types:\n",
        "            entities.append((ent.text, ent.label_))\n",
        "    return entities\n",
        "\n",
        "# Example paragraphs\n",
        "paragraph1 = \"Rescue workers are surveying the area after a suspected dirty bomb explosion. I can't believe Russia would commit these war crimes so openly. Its time for the world to stop these attacks now before its to late.\"\n",
        "paragraph2 = \"Thursday, killing at least five people, hours ahead of the first face-to-face meeting since the start of the war between the Turkish and Ukrainian leaders.Moscow meanwhile denied it had deployed any heavy weapons at the Russian-controlled Zaporizhzhia nuclear power plant in southern Ukraine where a recent escalation in fighting has increased fears of a nuclear disaster.The head of the Kharkiv region Oleg Synegubov said Moscows forces had launched eight missiles from Russian territory at around 0430 local time (0130 GMT) striking across the city.Three people died, including a child. Eight people, including two children, were rescued, the emergency services said.\"\n",
        "\n",
        "# Extract entities of specific types from the paragraphs\n",
        "entity_types_to_compare = ['GPE', 'PERSON', 'EVENT']  # GPE: Geopolitical Entity, PERSON: Person, EVENT: Event\n",
        "entities1 = extract_specific_entities(paragraph1, entity_types_to_compare)\n",
        "entities2 = extract_specific_entities(paragraph2, entity_types_to_compare)\n",
        "\n",
        "# Print the entities for each paragraph\n",
        "print(\"Entities in Paragraph 1:\")\n",
        "for entity, label in entities1:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "print(\"\\nEntities in Paragraph 2:\")\n",
        "for entity, label in entities2:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "# Create sets of entities for comparison\n",
        "entities_set1 = set(entities1)\n",
        "entities_set2 = set(entities2)\n",
        "\n",
        "# Find common entities in both paragraphs\n",
        "common_entities = entities_set1.intersection(entities_set2)\n",
        "print(\"\\nCommon Entities:\")\n",
        "for entity, label in common_entities:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "# Find unique entities in each paragraph\n",
        "unique_entities_paragraph1 = entities_set1 - common_entities\n",
        "unique_entities_paragraph2 = entities_set2 - common_entities\n",
        "\n",
        "print(\"\\nUnique Entities in Paragraph 1:\")\n",
        "for entity, label in unique_entities_paragraph1:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "print(\"\\nUnique Entities in Paragraph 2:\")\n",
        "for entity, label in unique_entities_paragraph2:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "# Check if facts for entities are consistent across both paragraphs\n",
        "consistent_facts = []\n",
        "inconsistent_facts = []\n",
        "for entity1 in entities_set1:\n",
        "    for entity2 in entities_set2:\n",
        "        if entity1[0] == entity2[0]:  # Check if entity text matches\n",
        "            consistent_facts.append(entity1)\n",
        "            break\n",
        "    else:\n",
        "        inconsistent_facts.append(entity1)\n",
        "\n",
        "print(\"\\nConsistent Facts:\")\n",
        "for entity, label in consistent_facts:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "print(\"\\nInconsistent Facts:\")\n",
        "for entity, label in inconsistent_facts:\n",
        "    print(f\"{entity} - {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhZNuX2hMkby",
        "outputId": "b0e60e8f-856e-41e5-d000-68c36fc9b72e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities in Paragraph 1:\n",
            "Russia - GPE\n",
            "\n",
            "Entities in Paragraph 2:\n",
            "Moscow - GPE\n",
            "Zaporizhzhia - PERSON\n",
            "Ukraine - GPE\n",
            "Oleg Synegubov - PERSON\n",
            "\n",
            "Common Entities:\n",
            "\n",
            "Unique Entities in Paragraph 1:\n",
            "Russia - GPE\n",
            "\n",
            "Unique Entities in Paragraph 2:\n",
            "Ukraine - GPE\n",
            "Oleg Synegubov - PERSON\n",
            "Moscow - GPE\n",
            "Zaporizhzhia - PERSON\n",
            "\n",
            "Consistent Facts:\n",
            "\n",
            "Inconsistent Facts:\n",
            "Russia - GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to calculate sentence embeddings using word embeddings\n",
        "def sentence_embedding(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    # Use average word vector as sentence embedding\n",
        "    return np.mean([token.vector for token in doc if not token.is_stop], axis=0)\n",
        "\n",
        "# Example paragraphs\n",
        "paragraph1 = \"Rescue workers are surveying the area after a suspected dirty bomb explosion. I can't believe Russia would commit these war crimes so openly. Its time for the world to stop these attacks now before its to late.\"\n",
        "paragraph2 = \"Thursday, killing at least five people, hours ahead of the first face-to-face meeting since the start of the war between the Turkish and Ukrainian leaders.Moscow meanwhile denied it had deployed any heavy weapons at the Russian-controlled Zaporizhzhia nuclear power plant in southern Ukraine where a recent escalation in fighting has increased fears of a nuclear disaster.The head of the Kharkiv region Oleg Synegubov said Moscows forces had launched eight missiles from Russian territory at around 0430 local time (0130 GMT) striking across the city.Three people died, including a child. Eight people, including two children, were rescued, the emergency services said.\"\n",
        "\n",
        "# Calculate sentence embeddings\n",
        "embedding1 = sentence_embedding(paragraph1)\n",
        "embedding2 = sentence_embedding(paragraph2)\n",
        "\n",
        "# Compute cosine similarity between the embeddings\n",
        "similarity = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "# Threshold for considering sentences consistent\n",
        "consistency_threshold = 0.8\n",
        "\n",
        "if similarity >= consistency_threshold:\n",
        "    print(\"The facts in the paragraphs are consistent.\")\n",
        "else:\n",
        "    print(\"The facts in the paragraphs are not consistent.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d8sU8krOTM3",
        "outputId": "e02a3d2a-5b5b-4ed6-f216-39616af56d3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The facts in the paragraphs are not consistent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to calculate sentence embeddings using word embeddings\n",
        "def sentence_embedding(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    # Use average word vector as sentence embedding\n",
        "    return np.mean([token.vector for token in doc if not token.is_stop], axis=0)\n",
        "\n",
        "# Example paragraphs\n",
        "paragraph1 = \"So senseless to target a building like a hostel. Multiple people killed. Hopefully the world will take notice of these tragic events soon.\"\n",
        "paragraph2 = \"Thursday, killing at least five people, hours ahead of the first face-to-face meeting since the start of the war between the Turkish and Ukrainian leaders.Moscow meanwhile denied it had deployed any heavy weapons at the Russian-controlled Zaporizhzhia nuclear power plant in southern Ukraine where a recent escalation in fighting has increased fears of a nuclear disaster.The head of the Kharkiv region Oleg Synegubov said Moscows forces had launched eight missiles from Russian territory at around 0430 local time (0130 GMT) striking across the city.Three people died, including a child. Eight people, including two children, were rescued, the emergency services said.\"\n",
        "\n",
        "# Calculate sentence embeddings\n",
        "embedding1 = sentence_embedding(paragraph1)\n",
        "embedding2 = sentence_embedding(paragraph2)\n",
        "\n",
        "# Compute cosine similarity between the embeddings\n",
        "similarity = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "# Threshold for considering sentences consistent\n",
        "consistency_threshold = 0.8\n",
        "\n",
        "if similarity >= consistency_threshold:\n",
        "    print(\"The facts in the paragraphs are consistent.\")\n",
        "else:\n",
        "    print(\"The facts in the paragraphs are not consistent.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOdtEp83Of8N",
        "outputId": "324d4d4c-1089-471f-f2c4-b0c81b4477a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The facts in the paragraphs are not consistent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the English language model for spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to calculate sentence embeddings using word embeddings\n",
        "def sentence_embedding(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    # Use average word vector as sentence embedding\n",
        "    return np.mean([token.vector for token in doc if not token.is_stop], axis=0)\n",
        "\n",
        "# Function to compare the facts in two paragraphs\n",
        "def compare_facts(paragraph1, paragraph2, consistency_threshold=0.8):\n",
        "    # Calculate sentence embeddings\n",
        "    embedding1 = sentence_embedding(paragraph1)\n",
        "    embedding2 = sentence_embedding(paragraph2)\n",
        "\n",
        "    # Compute cosine similarity between the embeddings\n",
        "    similarity = 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "    # Check if the facts are consistent\n",
        "    if similarity >= consistency_threshold:\n",
        "        return \"The facts in the paragraphs are consistent.\"\n",
        "    else:\n",
        "        return \"The facts in the paragraphs are not consistent.\"\n",
        "\n",
        "# Example paragraphs\n",
        "paragraph1 = \"So senseless to target a building like a hostel. Multiple people killed. Hopefully the world will take notice of these tragic events soon.\"\n",
        "paragraph2 = \"Thursday, killing at least five people, hours ahead of the first face-to-face meeting since the start of the war between the Turkish and Ukrainian leaders.Moscow meanwhile denied it had deployed any heavy weapons at the Russian-controlled Zaporizhzhia nuclear power plant in southern Ukraine where a recent escalation in fighting has increased fears of a nuclear disaster.The head of the Kharkiv region Oleg Synegubov said Moscows forces had launched eight missiles from Russian territory at around 0430 local time (0130 GMT) striking across the city.Three people died, including a child. Eight people, including two children, were rescued, the emergency services said.\"\n",
        "\n",
        "# Compare the facts in the paragraphs\n",
        "result = compare_facts(paragraph1, paragraph2)\n",
        "\n",
        "# Print the result\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PNarmIjO_8R",
        "outputId": "a8e2e99c-2f4e-4aaa-fd43-91149156bbe1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The facts in the paragraphs are not consistent.\n"
          ]
        }
      ]
    }
  ]
}